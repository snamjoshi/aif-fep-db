{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ground for paper scrapers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from paperscraper.arxiv import get_arxiv_papers_api\n",
    "from paperscraper.arxiv.utils import get_query_from_keywords\n",
    "from paperscraper.pubmed import get_pubmed_papers\n",
    "from paperscraper.pubmed.utils import get_query_from_keywords_and_date\n",
    "\n",
    "from src.utils import split_camel_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare query\n",
    "query = get_query_from_keywords_and_date(\n",
    "    keywords=[\"active inference\"], \n",
    "    start_date=\"2025/01/01\", \n",
    "    end_date=\"2025/02/01\")\n",
    "\n",
    "# Scrape PubMed\n",
    "papers = get_pubmed_papers(\n",
    "    query=query, \n",
    "    fields=[\"title\", \"authors\", \"date\", \"journal\", \"doi\"])\n",
    "\n",
    "# Change dates to year\n",
    "papers[\"date\"] = pd.to_datetime(papers[\"date\"])\n",
    "papers[\"date\"] = papers[\"date\"].dt.year\n",
    "\n",
    "# Format author column\n",
    "papers['authors'] = papers['authors'].apply(lambda name_list: [split_camel_case(name) for name in name_list])\n",
    "\n",
    "papers[\"authors\"] = papers[\"authors\"].apply(lambda name_list: \", \".join(name_list))\n",
    "\n",
    "# Reorder and rename columns\n",
    "papers = papers[[\"title\", \"authors\", \"journal\", \"date\", \"doi\"]]\n",
    "papers.columns = [\"title\", \"authors\", \"where_published\", \"year\", \"doi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArXiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all:active inference AND submittedDate:[202501010000 TO 202502010000]: 1117it [00:47, 23.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare query\n",
    "query = get_query_from_keywords(\n",
    "    keywords=[\"active inference\"], \n",
    "    start_date=\"2025-01-01\", \n",
    "    end_date=\"2025-02-01\")\n",
    "\n",
    "# Scrape ArXiv\n",
    "papers = get_arxiv_papers_api(\n",
    "    query=query, \n",
    "    fields=[\"title\", \"authors\", \"date\", \"journal\", \"doi\"])\n",
    "\n",
    "# Change dates to year\n",
    "papers[\"date\"] = pd.to_datetime(papers[\"date\"])\n",
    "papers[\"date\"] = papers[\"date\"].dt.year\n",
    "\n",
    "# Fill journal\n",
    "papers[\"journal\"] = [\"arXiv\"] * len(papers)\n",
    "\n",
    "# Reorder and rename columns\n",
    "papers = papers[[\"title\", \"authors\", \"journal\", \"date\", \"doi\"]]\n",
    "papers.columns = [\"title\", \"authors\", \"where_published\", \"year\", \"doi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>where_published</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Efficient LLM Inference with Activation Checkp...</td>\n",
       "      <td>Sanghyeon Lee, Hongbeen Kim, Soojin Hwang, Gus...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.01792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aging-aware CPU Core Management for Embodied C...</td>\n",
       "      <td>Tharindu B. Hewage, Shashikant Ilager, Maria R...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.15829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Active and transfer learning with partially Ba...</td>\n",
       "      <td>Sarah I. Allec, Maxim Ziatdinov</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.00952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dedicated Inference Engine and Binary-Weight N...</td>\n",
       "      <td>Tse-Wei Chen, Wei Tao, Dongyue Zhao, Kazuhiro ...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.01841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coded Deep Learning: Framework and Algorithm</td>\n",
       "      <td>En-hui Yang, Shayan Mohajer Hamidi</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.09849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>The ENUBET monitored neutrino beam and its imp...</td>\n",
       "      <td>ENUBET collaboration, L. Halić, F. Acerbi, I. ...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.04531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>Measurements of the Temperature and E-mode Pol...</td>\n",
       "      <td>T. -L. Chou, P. A. R. Ade, A. J. Anderson, J. ...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.06890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>Discovery of Ancient Globular Cluster Candidat...</td>\n",
       "      <td>Katherine E. Whitaker, Sam E. Cutler, Rupali C...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.07627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>FAUST XX. The chemical structure and temperatu...</td>\n",
       "      <td>J. Frediani, M. De Simone, L. Testi, L. Podio,...</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2501.19188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Dynamics of Magnetic Evaporative Beamline Cool...</td>\n",
       "      <td>A. Ashtari Esfahani, S. Bhagvati, S. Böser, M....</td>\n",
       "      <td>arXiv</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.48550/arXiv.2502.00188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1117 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Efficient LLM Inference with Activation Checkp...   \n",
       "1     Aging-aware CPU Core Management for Embodied C...   \n",
       "2     Active and transfer learning with partially Ba...   \n",
       "3     Dedicated Inference Engine and Binary-Weight N...   \n",
       "4          Coded Deep Learning: Framework and Algorithm   \n",
       "...                                                 ...   \n",
       "1112  The ENUBET monitored neutrino beam and its imp...   \n",
       "1113  Measurements of the Temperature and E-mode Pol...   \n",
       "1114  Discovery of Ancient Globular Cluster Candidat...   \n",
       "1115  FAUST XX. The chemical structure and temperatu...   \n",
       "1116  Dynamics of Magnetic Evaporative Beamline Cool...   \n",
       "\n",
       "                                                authors where_published  year  \\\n",
       "0     Sanghyeon Lee, Hongbeen Kim, Soojin Hwang, Gus...           arXiv  2025   \n",
       "1     Tharindu B. Hewage, Shashikant Ilager, Maria R...           arXiv  2025   \n",
       "2                       Sarah I. Allec, Maxim Ziatdinov           arXiv  2025   \n",
       "3     Tse-Wei Chen, Wei Tao, Dongyue Zhao, Kazuhiro ...           arXiv  2025   \n",
       "4                    En-hui Yang, Shayan Mohajer Hamidi           arXiv  2025   \n",
       "...                                                 ...             ...   ...   \n",
       "1112  ENUBET collaboration, L. Halić, F. Acerbi, I. ...           arXiv  2025   \n",
       "1113  T. -L. Chou, P. A. R. Ade, A. J. Anderson, J. ...           arXiv  2025   \n",
       "1114  Katherine E. Whitaker, Sam E. Cutler, Rupali C...           arXiv  2025   \n",
       "1115  J. Frediani, M. De Simone, L. Testi, L. Podio,...           arXiv  2025   \n",
       "1116  A. Ashtari Esfahani, S. Bhagvati, S. Böser, M....           arXiv  2025   \n",
       "\n",
       "                            doi  \n",
       "0     10.48550/arXiv.2501.01792  \n",
       "1     10.48550/arXiv.2501.15829  \n",
       "2     10.48550/arXiv.2501.00952  \n",
       "3     10.48550/arXiv.2501.01841  \n",
       "4     10.48550/arXiv.2501.09849  \n",
       "...                         ...  \n",
       "1112  10.48550/arXiv.2501.04531  \n",
       "1113  10.48550/arXiv.2501.06890  \n",
       "1114  10.48550/arXiv.2501.07627  \n",
       "1115  10.48550/arXiv.2501.19188  \n",
       "1116  10.48550/arXiv.2502.00188  \n",
       "\n",
       "[1117 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_and_dump_pubmed_papers(\n",
    "#     keywords=[\"active inference\"],\n",
    "#     output=\"data/tables/2025_04_04\",\n",
    "#     fields=[\"title\", \"authors\", \"date\", \"journal\", \"doi\"],\n",
    "#     start_date=\"2025/01/01\", end_date=\"2025/02/01\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from enum import Enum\n",
    "\n",
    "# class Scrapers(Enum):\n",
    "#     pubmed   = True\n",
    "#     arxiv    = True\n",
    "#     psyarxiv = False\n",
    "#     bioarxiv = False\n",
    "#     osf      = False\n",
    "#     zenodo   = False\n",
    "    \n",
    "# # archives = [\"pubmed\", \"arxiv\", \"psyarxiv\", \"bioarxiv\", \"osf\", \"zenodo\"]\n",
    "# archives = [\"afd\"]\n",
    "# archive_options = list(Scrapers.__members__)\n",
    "\n",
    "# supported = []\n",
    "# unsupported = []\n",
    "\n",
    "# for archive in archives:\n",
    "    \n",
    "#     if archive not in archive_options:\n",
    "#         raise Exception(f\"'{archive}' unrecgonized. Archive must be one of {archive_options}.\")\n",
    "\n",
    "#     if Scrapers[archive].value is False:\n",
    "#         unsupported.append(archive)\n",
    "#     else:\n",
    "#         supported.append(archive)\n",
    "        \n",
    "# assert len(unsupported) == 0, f\"Archives {unsupported} are not currently supported. Currently supported archives: {supported}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten_keywords(keywords: List[Union[str, List[str]]]) -> List[str]:\n",
    "#     flattened = []\n",
    "#     for item in keywords:\n",
    "#         if isinstance(item, str):\n",
    "#             flattened.append(item)\n",
    "#         elif isinstance(item, list):\n",
    "#             flattened.extend(flatten_keywords(item))  # recursive call\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported type in list: {type(item)}\")\n",
    "#     return flattened\n",
    "\n",
    "def flatten_keywords(keywords):\n",
    "    flattened = []\n",
    "    for item in keywords:\n",
    "        if isinstance(item, str):\n",
    "            flattened.append(item)\n",
    "        elif isinstance(item, list):\n",
    "            flattened.extend(flatten_keywords(item)) \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported type in list: {type(item)}\")\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/tables/2025_04_07/kw1__kw2__kw3__kw4__2025-04-07__14:29:39.757700.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date = str(creation_time).split(\" \")[0].replace(\"-\", \"_\")\n",
    "# keyword_string = '__'.join(flatten_keywords(keywords=keywords))\n",
    "# file_name = keyword_string + \"__\" + str(creation_time).replace(\" \", \"__\") + \".csv\"\n",
    "# outpath = \"data/tables/\" + date + \"/\" + file_name \n",
    "\n",
    "# outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\"],\n",
    "    \"age\": [25, 30]\n",
    "})\n",
    "\n",
    "keywords = [[\"kw1\"], [\"kw2\", \"kw3\"], [\"kw4\"]]\n",
    "creation_time = datetime.now()\n",
    "\n",
    "date = str(creation_time).split(\" \")[0].replace(\"-\", \"_\")\n",
    "dir_path = os.path.join(\"data/tables\", date)\n",
    "os.makedirs(dir_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "keyword_string = '__'.join(flatten_keywords(keywords=keywords))\n",
    "file_name = keyword_string + \"__\" + str(creation_time).replace(\" \", \"__\") + \".csv\"\n",
    "outpath = os.path.join(dir_path, file_name)\n",
    "df.to_csv(outpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025_04_07'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
